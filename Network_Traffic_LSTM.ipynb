{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network Traffic LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW1Gaw-qN9ql",
        "outputId": "b2939873-3dee-4034-e666-959afe1538fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, SimpleRNN, GRU, LSTM, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "VVEUjF1jOL4s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "df_traffic = pd.read_csv(io.BytesIO(uploaded['traffic.csv']))\n",
        "df_traffic.shape\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "tzegniJx47Qg",
        "outputId": "6c267fbe-f775-453d-81e2-f0d2b12773e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0e270596-0f38-4f76-987a-60e871b95d18\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0e270596-0f38-4f76-987a-60e871b95d18\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving traffic.csv to traffic.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_traffic.isnull().sum()\n",
        "## No Null values\n",
        "df_traffic.head(21)\n",
        "# It's a sequence of length 10."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "URU5sMag9XOP",
        "outputId": "043fb4dc-be78-4374-dc65-7b29cc12d2fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-065ddb24-4eea-48ef-ba87-cce5adb7a479\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_no</th>\n",
              "      <th>sample_id</th>\n",
              "      <th>traffic</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088819</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.480121</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.560106</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.341833</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317495</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.544496</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414178</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.386035</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037407</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020645</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.458865</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.539305</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.064521</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.257540</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.519951</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.053860</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.490556</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.469363</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.285217</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.349931</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.071146</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-065ddb24-4eea-48ef-ba87-cce5adb7a479')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-065ddb24-4eea-48ef-ba87-cce5adb7a479 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-065ddb24-4eea-48ef-ba87-cce5adb7a479');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    sequence_no  sample_id   traffic  target\n",
              "0           0.0        0.0  0.088819     0.0\n",
              "1           1.0        0.0  0.480121     0.0\n",
              "2           2.0        0.0  0.560106     0.0\n",
              "3           3.0        0.0  0.341833     0.0\n",
              "4           4.0        0.0  0.317495     0.0\n",
              "5           5.0        0.0  0.544496     0.0\n",
              "6           6.0        0.0  0.414178     0.0\n",
              "7           7.0        0.0  0.386035     0.0\n",
              "8           8.0        0.0  0.037407     0.0\n",
              "9           9.0        0.0  0.020645     0.0\n",
              "10          0.0        1.0  0.458865     0.0\n",
              "11          1.0        1.0  0.539305     0.0\n",
              "12          2.0        1.0  0.064521     0.0\n",
              "13          3.0        1.0  0.257540     0.0\n",
              "14          4.0        1.0  0.519951     0.0\n",
              "15          5.0        1.0  0.053860     0.0\n",
              "16          6.0        1.0  0.490556     0.0\n",
              "17          7.0        1.0  0.469363     0.0\n",
              "18          8.0        1.0  0.285217     0.0\n",
              "19          9.0        1.0  0.349931     0.0\n",
              "20          0.0        2.0  0.071146     0.0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df_traffic.groupby('sample_id').target.nunique('target')>1).sum()\n",
        "df_traffic.target.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj0Lon4s45Zv",
        "outputId": "4461f9ca-ac8f-40bc-d081-9d0a205c507c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating a dataframe with sequence length of 10 with 10 targets\n",
        "X=[]\n",
        "T=10\n",
        "y=[]\n",
        "for i in np.arange(0,df_traffic.shape[0],10) :\n",
        "  X.append(df_traffic.traffic[i:i+T])\n",
        "  y.append(df_traffic.target[i:i+T].mean())\n",
        "X=np.array(X).reshape(-1,T)\n",
        "y=np.array(y)\n",
        "print(\"X.shape\", X.shape, \"Y.shape\", y.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7bUGvJA9kLZ",
        "outputId": "ddf980fd-a891-4d38-d693-b62429d32086"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape (20000, 10) Y.shape (20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "tbYXH64ZIAQQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Now try RNN/LSTM model\n",
        "D=1   # As we have only 1 feature as \"traffic\"\n",
        "X = X.reshape(-1, T, 1) # make it N x T x D\n",
        "N=20000\n",
        "T=10\n",
        "# make the RNN\n",
        "i = Input(shape=(T, D))\n",
        "x = LSTM(50)(i)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "model = Model(i, x)\n",
        "model.compile(\n",
        " loss='sparse_categorical_crossentropy',\n",
        "# loss='binary_crossentropy',\n",
        "  optimizer=Adam(lr=0.01),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# train the RNN\n",
        "r = model.fit(\n",
        "  X_train,y_train,\n",
        "  batch_size=150,\n",
        "  epochs=50,\n",
        "  validation_data=(X_test,y_test),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGwme-1vGBAR",
        "outputId": "a6ac520b-c8c0-42d0-c528-3c8aa89f6c51"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "94/94 [==============================] - 3s 14ms/step - loss: 0.8166 - accuracy: 0.6322 - val_loss: 0.6038 - val_accuracy: 0.7335\n",
            "Epoch 2/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.4742 - accuracy: 0.7961 - val_loss: 0.3739 - val_accuracy: 0.8495\n",
            "Epoch 3/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.3458 - accuracy: 0.8653 - val_loss: 0.2556 - val_accuracy: 0.9017\n",
            "Epoch 4/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.2635 - accuracy: 0.8979 - val_loss: 0.2378 - val_accuracy: 0.9108\n",
            "Epoch 5/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.2339 - accuracy: 0.9131 - val_loss: 0.1958 - val_accuracy: 0.9273\n",
            "Epoch 6/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1917 - accuracy: 0.9312 - val_loss: 0.1934 - val_accuracy: 0.9287\n",
            "Epoch 7/50\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.1759 - accuracy: 0.9368 - val_loss: 0.1487 - val_accuracy: 0.9443\n",
            "Epoch 8/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1729 - accuracy: 0.9388 - val_loss: 0.1766 - val_accuracy: 0.9332\n",
            "Epoch 9/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1632 - accuracy: 0.9443 - val_loss: 0.1674 - val_accuracy: 0.9358\n",
            "Epoch 10/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1483 - accuracy: 0.9491 - val_loss: 0.1279 - val_accuracy: 0.9548\n",
            "Epoch 11/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1407 - accuracy: 0.9519 - val_loss: 0.1369 - val_accuracy: 0.9548\n",
            "Epoch 12/50\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.1406 - accuracy: 0.9498 - val_loss: 0.1446 - val_accuracy: 0.9510\n",
            "Epoch 13/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1379 - accuracy: 0.9506 - val_loss: 0.1339 - val_accuracy: 0.9520\n",
            "Epoch 14/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1391 - accuracy: 0.9534 - val_loss: 0.1126 - val_accuracy: 0.9617\n",
            "Epoch 15/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1162 - accuracy: 0.9606 - val_loss: 0.1532 - val_accuracy: 0.9455\n",
            "Epoch 16/50\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.1227 - accuracy: 0.9574 - val_loss: 0.1176 - val_accuracy: 0.9573\n",
            "Epoch 17/50\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.1265 - accuracy: 0.9571 - val_loss: 0.1068 - val_accuracy: 0.9638\n",
            "Epoch 18/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1171 - accuracy: 0.9595 - val_loss: 0.1108 - val_accuracy: 0.9642\n",
            "Epoch 19/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1193 - accuracy: 0.9610 - val_loss: 0.1053 - val_accuracy: 0.9627\n",
            "Epoch 20/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1005 - accuracy: 0.9664 - val_loss: 0.0904 - val_accuracy: 0.9708\n",
            "Epoch 21/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1053 - accuracy: 0.9646 - val_loss: 0.0999 - val_accuracy: 0.9670\n",
            "Epoch 22/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0984 - accuracy: 0.9671 - val_loss: 0.0921 - val_accuracy: 0.9692\n",
            "Epoch 23/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0976 - accuracy: 0.9689 - val_loss: 0.1184 - val_accuracy: 0.9578\n",
            "Epoch 24/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1121 - accuracy: 0.9633 - val_loss: 0.1331 - val_accuracy: 0.9560\n",
            "Epoch 25/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1044 - accuracy: 0.9654 - val_loss: 0.0941 - val_accuracy: 0.9717\n",
            "Epoch 26/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0946 - accuracy: 0.9686 - val_loss: 0.0991 - val_accuracy: 0.9645\n",
            "Epoch 27/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.9707 - val_loss: 0.0924 - val_accuracy: 0.9712\n",
            "Epoch 28/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.1042 - accuracy: 0.9649 - val_loss: 0.1539 - val_accuracy: 0.9458\n",
            "Epoch 29/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0927 - accuracy: 0.9692 - val_loss: 0.0943 - val_accuracy: 0.9718\n",
            "Epoch 30/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0857 - accuracy: 0.9721 - val_loss: 0.0774 - val_accuracy: 0.9750\n",
            "Epoch 31/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0856 - accuracy: 0.9718 - val_loss: 0.1486 - val_accuracy: 0.9430\n",
            "Epoch 32/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0954 - accuracy: 0.9681 - val_loss: 0.0883 - val_accuracy: 0.9703\n",
            "Epoch 33/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0912 - accuracy: 0.9704 - val_loss: 0.1374 - val_accuracy: 0.9528\n",
            "Epoch 34/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0888 - accuracy: 0.9706 - val_loss: 0.0710 - val_accuracy: 0.9785\n",
            "Epoch 35/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0850 - accuracy: 0.9714 - val_loss: 0.0712 - val_accuracy: 0.9795\n",
            "Epoch 36/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.9704 - val_loss: 0.0816 - val_accuracy: 0.9765\n",
            "Epoch 37/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0777 - accuracy: 0.9738 - val_loss: 0.0916 - val_accuracy: 0.9638\n",
            "Epoch 38/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0751 - accuracy: 0.9764 - val_loss: 0.1222 - val_accuracy: 0.9535\n",
            "Epoch 39/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0843 - accuracy: 0.9741 - val_loss: 0.0705 - val_accuracy: 0.9778\n",
            "Epoch 40/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0798 - accuracy: 0.9745 - val_loss: 0.0852 - val_accuracy: 0.9733\n",
            "Epoch 41/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0780 - accuracy: 0.9743 - val_loss: 0.0829 - val_accuracy: 0.9705\n",
            "Epoch 42/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0842 - accuracy: 0.9723 - val_loss: 0.1005 - val_accuracy: 0.9668\n",
            "Epoch 43/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0757 - accuracy: 0.9751 - val_loss: 0.0766 - val_accuracy: 0.9770\n",
            "Epoch 44/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0685 - accuracy: 0.9791 - val_loss: 0.0922 - val_accuracy: 0.9675\n",
            "Epoch 45/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0649 - accuracy: 0.9800 - val_loss: 0.0841 - val_accuracy: 0.9697\n",
            "Epoch 46/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: 0.0957 - val_accuracy: 0.9687\n",
            "Epoch 47/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0679 - accuracy: 0.9774 - val_loss: 0.0698 - val_accuracy: 0.9783\n",
            "Epoch 48/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0720 - accuracy: 0.9774 - val_loss: 0.1143 - val_accuracy: 0.9677\n",
            "Epoch 49/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0643 - accuracy: 0.9806 - val_loss: 0.0841 - val_accuracy: 0.9752\n",
            "Epoch 50/50\n",
            "94/94 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.9722 - val_loss: 0.0935 - val_accuracy: 0.9680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fBzwCMd87RzC",
        "outputId": "4f939b37-fd2c-4c15-931d-15d6a315ef47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ECmbU26VGJ18",
        "outputId": "aae057ce-f43e-4b03-c8f9-48c1c98b04f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "#  print('Accuracy of  Neural Network Classifier on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n",
        "#  print(confusion_matrix(y_test,predictions))\n",
        "#  print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "sQnZSPx9Uaom"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat=[]\n",
        "for pred in predictions:\n",
        "  y_hat.append(pred.argmax())\n",
        "  \n",
        "print('Accuracy of  Neural Network Classifier on test set: {:.2f}'.format(metrics.accuracy_score(y_test,y_hat) ))\n",
        "print(confusion_matrix(y_test,y_hat))\n",
        "print(classification_report(y_test,y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jiGJZjIahgd",
        "outputId": "0428d681-e08a-47c7-91d6-f85eb55bc617"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of  Neural Network Classifier on test set: 0.97\n",
            "[[1471   14    0    0]\n",
            " [  35 1441   55    1]\n",
            " [   0   30 1428   53]\n",
            " [   0    0    4 1468]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98      1485\n",
            "         1.0       0.97      0.94      0.96      1532\n",
            "         2.0       0.96      0.95      0.95      1511\n",
            "         3.0       0.96      1.00      0.98      1472\n",
            "\n",
            "    accuracy                           0.97      6000\n",
            "   macro avg       0.97      0.97      0.97      6000\n",
            "weighted avg       0.97      0.97      0.97      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Defining a function to find the best parameters for LSTM\n",
        "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
        "    \n",
        "    # Defining the list of hyper parameters to try\n",
        "    learning_rate_list=[0.05,0.1]\n",
        "    hidden_unit_list=[50]\n",
        "    batch_size_list=[200]\n",
        "    epoch_list  =   [75,100]\n",
        "    \n",
        "    print(X_train.shape,X_test.shape)\n",
        "    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
        "    \n",
        "    # initializing the trials\n",
        "    TrialNumber=0\n",
        "    for batch_size_trial in batch_size_list:\n",
        "        for epochs_trial in epoch_list:\n",
        "            for lr_trial in learning_rate_list:\n",
        "                for hidden_unit_trial in hidden_unit_list:\n",
        "                    TrialNumber+=1\n",
        "        \n",
        "                    # make the RNN\n",
        "                    i = Input(shape=(T, D))\n",
        "                    x = LSTM(hidden_unit_trial)(i)\n",
        "                    x = Dense(4, activation='softmax')(x)\n",
        "                    model = Model(i, x)\n",
        "                    model.compile(\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    # loss='binary_crossentropy',\n",
        "                    optimizer=Adam(lr=lr_trial),\n",
        "                      metrics=['accuracy']\n",
        "                    )\n",
        "\n",
        "                  # train the RNN\n",
        "                    r = model.fit(\n",
        "                    X_train,y_train,\n",
        "                    batch_size=batch_size_trial,\n",
        "                    epochs=epochs_trial\n",
        "                    )\n",
        "                    predictions = model.predict(X_test)\n",
        "                    y_hat=[]\n",
        "                    for pred in predictions:\n",
        "                      y_hat.append(pred.argmax())\n",
        "\n",
        "\n",
        "                    print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, \\\n",
        "                      'LR_unit:',lr_trial,'Hidden_Unit:',hidden_unit_trial,'Accuracy:',metrics.accuracy_score(y_test,y_hat) )\n",
        "            \n",
        "                SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial),metrics.accuracy_score(y_test,y_hat) ]],\n",
        "                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n",
        "    return(SearchResultsData)\n",
        " \n"
      ],
      "metadata": {
        "id": "8ssXzksjaMTL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResultsData=FunctionFindBestParams(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE4ayrV8hJvm",
        "outputId": "076c2e21-781b-4259-c0a3-01cbda849315"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14000, 10) (6000, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "70/70 [==============================] - 2s 9ms/step - loss: 0.8660 - accuracy: 0.6153\n",
            "Epoch 2/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3965 - accuracy: 0.8470\n",
            "Epoch 3/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2386 - accuracy: 0.9132\n",
            "Epoch 4/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2039 - accuracy: 0.9277\n",
            "Epoch 5/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1663 - accuracy: 0.9436\n",
            "Epoch 6/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1495 - accuracy: 0.9476\n",
            "Epoch 7/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1318 - accuracy: 0.9549\n",
            "Epoch 8/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1440 - accuracy: 0.9525\n",
            "Epoch 9/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1248 - accuracy: 0.9581\n",
            "Epoch 10/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1113 - accuracy: 0.9639\n",
            "Epoch 11/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1289 - accuracy: 0.9575\n",
            "Epoch 12/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1008 - accuracy: 0.9662\n",
            "Epoch 13/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1172 - accuracy: 0.9614\n",
            "Epoch 14/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.1006 - accuracy: 0.9668\n",
            "Epoch 15/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0938 - accuracy: 0.9696\n",
            "Epoch 16/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0820 - accuracy: 0.9739\n",
            "Epoch 17/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0927 - accuracy: 0.9689\n",
            "Epoch 18/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0881 - accuracy: 0.9716\n",
            "Epoch 19/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0940 - accuracy: 0.9696\n",
            "Epoch 20/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0950 - accuracy: 0.9679\n",
            "Epoch 21/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0809 - accuracy: 0.9732\n",
            "Epoch 22/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0774 - accuracy: 0.9738\n",
            "Epoch 23/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0732 - accuracy: 0.9758\n",
            "Epoch 24/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0920 - accuracy: 0.9696\n",
            "Epoch 25/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1026 - accuracy: 0.9663\n",
            "Epoch 26/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0735 - accuracy: 0.9774\n",
            "Epoch 27/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0842 - accuracy: 0.9734\n",
            "Epoch 28/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0737 - accuracy: 0.9768\n",
            "Epoch 29/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0755 - accuracy: 0.9739\n",
            "Epoch 30/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0676 - accuracy: 0.9786\n",
            "Epoch 31/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0721 - accuracy: 0.9764\n",
            "Epoch 32/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0800 - accuracy: 0.9739\n",
            "Epoch 33/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0814 - accuracy: 0.9736\n",
            "Epoch 34/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0724 - accuracy: 0.9782\n",
            "Epoch 35/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0689 - accuracy: 0.9790\n",
            "Epoch 36/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0750 - accuracy: 0.9753\n",
            "Epoch 37/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0782 - accuracy: 0.9754\n",
            "Epoch 38/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0645 - accuracy: 0.9790\n",
            "Epoch 39/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0732 - accuracy: 0.9759\n",
            "Epoch 40/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0679 - accuracy: 0.9784\n",
            "Epoch 41/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0591 - accuracy: 0.9825\n",
            "Epoch 42/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0741 - accuracy: 0.9769\n",
            "Epoch 43/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9783\n",
            "Epoch 44/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9769\n",
            "Epoch 45/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0748 - accuracy: 0.9759\n",
            "Epoch 46/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0647 - accuracy: 0.9789\n",
            "Epoch 47/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0596 - accuracy: 0.9824\n",
            "Epoch 48/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9774\n",
            "Epoch 49/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0611 - accuracy: 0.9804\n",
            "Epoch 50/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9739\n",
            "Epoch 51/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0634 - accuracy: 0.9798\n",
            "Epoch 52/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0637 - accuracy: 0.9794\n",
            "Epoch 53/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0629 - accuracy: 0.9813\n",
            "Epoch 54/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0649 - accuracy: 0.9792\n",
            "Epoch 55/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0593 - accuracy: 0.9810\n",
            "Epoch 56/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0776 - accuracy: 0.9749\n",
            "Epoch 57/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0578 - accuracy: 0.9826\n",
            "Epoch 58/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0530 - accuracy: 0.9842\n",
            "Epoch 59/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0652 - accuracy: 0.9801\n",
            "Epoch 60/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0496 - accuracy: 0.9849\n",
            "Epoch 61/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0585 - accuracy: 0.9814\n",
            "Epoch 62/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0769 - accuracy: 0.9749\n",
            "Epoch 63/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0579 - accuracy: 0.9822\n",
            "Epoch 64/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0595 - accuracy: 0.9816\n",
            "Epoch 65/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0559 - accuracy: 0.9840\n",
            "Epoch 66/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0610 - accuracy: 0.9811\n",
            "Epoch 67/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0548 - accuracy: 0.9833\n",
            "Epoch 68/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0497 - accuracy: 0.9846\n",
            "Epoch 69/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0589 - accuracy: 0.9821\n",
            "Epoch 70/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0593 - accuracy: 0.9819\n",
            "Epoch 71/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0561 - accuracy: 0.9827\n",
            "Epoch 72/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0579 - accuracy: 0.9834\n",
            "Epoch 73/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0559 - accuracy: 0.9819\n",
            "Epoch 74/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0600 - accuracy: 0.9817\n",
            "Epoch 75/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0553 - accuracy: 0.9829\n",
            "1 Parameters: batch_size: 200 - epochs: 75 LR_unit: 0.05 Hidden_Unit: 50 Accuracy: 0.9811666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "70/70 [==============================] - 2s 8ms/step - loss: 1.0556 - accuracy: 0.5239\n",
            "Epoch 2/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.5720 - accuracy: 0.7471\n",
            "Epoch 3/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.4317 - accuracy: 0.8209\n",
            "Epoch 4/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2750 - accuracy: 0.8943\n",
            "Epoch 5/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2635 - accuracy: 0.9007\n",
            "Epoch 6/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2161 - accuracy: 0.9193\n",
            "Epoch 7/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1795 - accuracy: 0.9344\n",
            "Epoch 8/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1713 - accuracy: 0.9395\n",
            "Epoch 9/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1676 - accuracy: 0.9424\n",
            "Epoch 10/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1578 - accuracy: 0.9441\n",
            "Epoch 11/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9511\n",
            "Epoch 12/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1338 - accuracy: 0.9529\n",
            "Epoch 13/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1261 - accuracy: 0.9569\n",
            "Epoch 14/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.1325 - accuracy: 0.9543\n",
            "Epoch 15/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1408 - accuracy: 0.9519\n",
            "Epoch 16/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1247 - accuracy: 0.9584\n",
            "Epoch 17/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1247 - accuracy: 0.9584\n",
            "Epoch 18/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1224 - accuracy: 0.9616\n",
            "Epoch 19/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1050 - accuracy: 0.9661\n",
            "Epoch 20/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1060 - accuracy: 0.9671\n",
            "Epoch 21/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1161 - accuracy: 0.9611\n",
            "Epoch 22/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1024 - accuracy: 0.9666\n",
            "Epoch 23/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1026 - accuracy: 0.9685\n",
            "Epoch 24/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0938 - accuracy: 0.9700\n",
            "Epoch 25/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1046 - accuracy: 0.9680\n",
            "Epoch 26/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0930 - accuracy: 0.9709\n",
            "Epoch 27/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0836 - accuracy: 0.9725\n",
            "Epoch 28/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1029 - accuracy: 0.9681\n",
            "Epoch 29/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0929 - accuracy: 0.9704\n",
            "Epoch 30/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0750 - accuracy: 0.9764\n",
            "Epoch 31/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0740 - accuracy: 0.9770\n",
            "Epoch 32/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0787 - accuracy: 0.9767\n",
            "Epoch 33/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1088 - accuracy: 0.9641\n",
            "Epoch 34/75\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0919 - accuracy: 0.9703\n",
            "Epoch 35/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0752 - accuracy: 0.9768\n",
            "Epoch 36/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0847 - accuracy: 0.9746\n",
            "Epoch 37/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0888 - accuracy: 0.9726\n",
            "Epoch 38/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0868 - accuracy: 0.9734\n",
            "Epoch 39/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0728 - accuracy: 0.9761\n",
            "Epoch 40/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0752 - accuracy: 0.9766\n",
            "Epoch 41/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0689 - accuracy: 0.9789\n",
            "Epoch 42/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0705 - accuracy: 0.9776\n",
            "Epoch 43/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0885 - accuracy: 0.9723\n",
            "Epoch 44/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0753 - accuracy: 0.9767\n",
            "Epoch 45/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0755 - accuracy: 0.9774\n",
            "Epoch 46/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0660 - accuracy: 0.9804\n",
            "Epoch 47/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0793 - accuracy: 0.9756\n",
            "Epoch 48/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0710 - accuracy: 0.9797\n",
            "Epoch 49/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0644 - accuracy: 0.9812\n",
            "Epoch 50/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0661 - accuracy: 0.9804\n",
            "Epoch 51/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0686 - accuracy: 0.9782\n",
            "Epoch 52/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0585 - accuracy: 0.9834\n",
            "Epoch 53/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0650 - accuracy: 0.9801\n",
            "Epoch 54/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0584 - accuracy: 0.9819\n",
            "Epoch 55/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0934 - accuracy: 0.9706\n",
            "Epoch 56/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0943 - accuracy: 0.9688\n",
            "Epoch 57/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0714 - accuracy: 0.9768\n",
            "Epoch 58/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0705 - accuracy: 0.9773\n",
            "Epoch 59/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0869 - accuracy: 0.9735\n",
            "Epoch 60/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0620 - accuracy: 0.9802\n",
            "Epoch 61/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0590 - accuracy: 0.9816\n",
            "Epoch 62/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0587 - accuracy: 0.9824\n",
            "Epoch 63/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0661 - accuracy: 0.9796\n",
            "Epoch 64/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0660 - accuracy: 0.9801\n",
            "Epoch 65/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0687 - accuracy: 0.9783\n",
            "Epoch 66/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0706 - accuracy: 0.9794\n",
            "Epoch 67/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0957 - accuracy: 0.9711\n",
            "Epoch 68/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0707 - accuracy: 0.9781\n",
            "Epoch 69/75\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.0609 - accuracy: 0.9816\n",
            "Epoch 70/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0615 - accuracy: 0.9807\n",
            "Epoch 71/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0647 - accuracy: 0.9803\n",
            "Epoch 72/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0592 - accuracy: 0.9806\n",
            "Epoch 73/75\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0656 - accuracy: 0.9794\n",
            "Epoch 74/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0687 - accuracy: 0.9795\n",
            "Epoch 75/75\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0766 - accuracy: 0.9751\n",
            "2 Parameters: batch_size: 200 - epochs: 75 LR_unit: 0.1 Hidden_Unit: 50 Accuracy: 0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "70/70 [==============================] - 2s 8ms/step - loss: 0.7612 - accuracy: 0.6579\n",
            "Epoch 2/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2868 - accuracy: 0.8911\n",
            "Epoch 3/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2249 - accuracy: 0.9183\n",
            "Epoch 4/100\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.2054 - accuracy: 0.9270\n",
            "Epoch 5/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1886 - accuracy: 0.9307\n",
            "Epoch 6/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1353 - accuracy: 0.9534\n",
            "Epoch 7/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1503 - accuracy: 0.9491\n",
            "Epoch 8/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1207 - accuracy: 0.9587\n",
            "Epoch 9/100\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 0.1259 - accuracy: 0.9569\n",
            "Epoch 10/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1175 - accuracy: 0.9604\n",
            "Epoch 11/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1239 - accuracy: 0.9588\n",
            "Epoch 12/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1124 - accuracy: 0.9616\n",
            "Epoch 13/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1042 - accuracy: 0.9666\n",
            "Epoch 14/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0945 - accuracy: 0.9694\n",
            "Epoch 15/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1126 - accuracy: 0.9624\n",
            "Epoch 16/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0851 - accuracy: 0.9721\n",
            "Epoch 17/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0959 - accuracy: 0.9699\n",
            "Epoch 18/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.9636\n",
            "Epoch 19/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0800 - accuracy: 0.9739\n",
            "Epoch 20/100\n",
            "70/70 [==============================] - 1s 11ms/step - loss: 0.0964 - accuracy: 0.9698\n",
            "Epoch 21/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0818 - accuracy: 0.9731\n",
            "Epoch 22/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0878 - accuracy: 0.9719\n",
            "Epoch 23/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0853 - accuracy: 0.9724\n",
            "Epoch 24/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0820 - accuracy: 0.9742\n",
            "Epoch 25/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0832 - accuracy: 0.9740\n",
            "Epoch 26/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0842 - accuracy: 0.9724\n",
            "Epoch 27/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0814 - accuracy: 0.9752\n",
            "Epoch 28/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0736 - accuracy: 0.9760\n",
            "Epoch 29/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0699 - accuracy: 0.9775\n",
            "Epoch 30/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0794 - accuracy: 0.9746\n",
            "Epoch 31/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0853 - accuracy: 0.9711\n",
            "Epoch 32/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0749 - accuracy: 0.9754\n",
            "Epoch 33/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0834 - accuracy: 0.9741\n",
            "Epoch 34/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0643 - accuracy: 0.9804\n",
            "Epoch 35/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0701 - accuracy: 0.9780\n",
            "Epoch 36/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0612 - accuracy: 0.9813\n",
            "Epoch 37/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0698 - accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0638 - accuracy: 0.9781\n",
            "Epoch 39/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0688 - accuracy: 0.9774\n",
            "Epoch 40/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0694 - accuracy: 0.9776\n",
            "Epoch 41/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0656 - accuracy: 0.9792\n",
            "Epoch 42/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0657 - accuracy: 0.9800\n",
            "Epoch 43/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9753\n",
            "Epoch 44/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0777 - accuracy: 0.9751\n",
            "Epoch 45/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0769 - accuracy: 0.9752\n",
            "Epoch 46/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0643 - accuracy: 0.9795\n",
            "Epoch 47/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0670 - accuracy: 0.9801\n",
            "Epoch 48/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0583 - accuracy: 0.9821\n",
            "Epoch 49/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0621 - accuracy: 0.9815\n",
            "Epoch 50/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0598 - accuracy: 0.9817\n",
            "Epoch 51/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0592 - accuracy: 0.9813\n",
            "Epoch 52/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0841 - accuracy: 0.9745\n",
            "Epoch 53/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0721 - accuracy: 0.9779\n",
            "Epoch 54/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0615 - accuracy: 0.9806\n",
            "Epoch 55/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0662 - accuracy: 0.9791\n",
            "Epoch 56/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0653 - accuracy: 0.9788\n",
            "Epoch 57/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0638 - accuracy: 0.9806\n",
            "Epoch 58/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0565 - accuracy: 0.9813\n",
            "Epoch 59/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0546 - accuracy: 0.9834\n",
            "Epoch 60/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0554 - accuracy: 0.9823\n",
            "Epoch 61/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0518 - accuracy: 0.9841\n",
            "Epoch 62/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0694 - accuracy: 0.9783\n",
            "Epoch 63/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0558 - accuracy: 0.9822\n",
            "Epoch 64/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0673 - accuracy: 0.9789\n",
            "Epoch 65/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0589 - accuracy: 0.9816\n",
            "Epoch 66/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0650 - accuracy: 0.9784\n",
            "Epoch 67/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0570 - accuracy: 0.9826\n",
            "Epoch 68/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0568 - accuracy: 0.9825\n",
            "Epoch 69/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0545 - accuracy: 0.9828\n",
            "Epoch 70/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0539 - accuracy: 0.9833\n",
            "Epoch 71/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0527 - accuracy: 0.9829\n",
            "Epoch 72/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0590 - accuracy: 0.9811\n",
            "Epoch 73/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0649 - accuracy: 0.9800\n",
            "Epoch 74/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0710 - accuracy: 0.9780\n",
            "Epoch 75/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0554 - accuracy: 0.9832\n",
            "Epoch 76/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0508 - accuracy: 0.9842\n",
            "Epoch 77/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0569 - accuracy: 0.9812\n",
            "Epoch 78/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0906 - accuracy: 0.9712\n",
            "Epoch 79/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0554 - accuracy: 0.9820\n",
            "Epoch 80/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0640 - accuracy: 0.9807\n",
            "Epoch 81/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0612 - accuracy: 0.9807\n",
            "Epoch 82/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9844\n",
            "Epoch 83/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0490 - accuracy: 0.9843\n",
            "Epoch 84/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0478 - accuracy: 0.9864\n",
            "Epoch 85/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0650 - accuracy: 0.9793\n",
            "Epoch 86/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0626 - accuracy: 0.9804\n",
            "Epoch 87/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0463 - accuracy: 0.9854\n",
            "Epoch 88/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0525 - accuracy: 0.9839\n",
            "Epoch 89/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0504 - accuracy: 0.9839\n",
            "Epoch 90/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0518 - accuracy: 0.9838\n",
            "Epoch 91/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0631 - accuracy: 0.9805\n",
            "Epoch 92/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0556 - accuracy: 0.9824\n",
            "Epoch 93/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0640 - accuracy: 0.9806\n",
            "Epoch 94/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0576 - accuracy: 0.9818\n",
            "Epoch 95/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0647 - accuracy: 0.9806\n",
            "Epoch 96/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0532 - accuracy: 0.9849\n",
            "Epoch 97/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0429 - accuracy: 0.9872\n",
            "Epoch 98/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0512 - accuracy: 0.9840\n",
            "Epoch 99/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0571 - accuracy: 0.9829\n",
            "Epoch 100/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0519 - accuracy: 0.9846\n",
            "3 Parameters: batch_size: 200 - epochs: 100 LR_unit: 0.05 Hidden_Unit: 50 Accuracy: 0.9811666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "70/70 [==============================] - 2s 9ms/step - loss: 1.4608 - accuracy: 0.2463\n",
            "Epoch 2/100\n",
            "70/70 [==============================] - 1s 8ms/step - loss: 1.1431 - accuracy: 0.4568\n",
            "Epoch 3/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.8121 - accuracy: 0.6246\n",
            "Epoch 4/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.7056 - accuracy: 0.6784\n",
            "Epoch 5/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.6436 - accuracy: 0.7206\n",
            "Epoch 6/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.5072 - accuracy: 0.7964\n",
            "Epoch 7/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3365 - accuracy: 0.8729\n",
            "Epoch 8/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3432 - accuracy: 0.8779\n",
            "Epoch 9/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2694 - accuracy: 0.9071\n",
            "Epoch 10/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2272 - accuracy: 0.9229\n",
            "Epoch 11/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2043 - accuracy: 0.9349\n",
            "Epoch 12/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2247 - accuracy: 0.9289\n",
            "Epoch 13/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2608 - accuracy: 0.9181\n",
            "Epoch 14/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1803 - accuracy: 0.9437\n",
            "Epoch 15/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2345 - accuracy: 0.9269\n",
            "Epoch 16/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2021 - accuracy: 0.9379\n",
            "Epoch 17/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2110 - accuracy: 0.9361\n",
            "Epoch 18/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1830 - accuracy: 0.9410\n",
            "Epoch 19/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1318 - accuracy: 0.9593\n",
            "Epoch 20/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1803 - accuracy: 0.9461\n",
            "Epoch 21/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1361 - accuracy: 0.9605\n",
            "Epoch 22/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2190 - accuracy: 0.9301\n",
            "Epoch 23/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1797 - accuracy: 0.9453\n",
            "Epoch 24/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1810 - accuracy: 0.9455\n",
            "Epoch 25/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1900 - accuracy: 0.9406\n",
            "Epoch 26/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1712 - accuracy: 0.9477\n",
            "Epoch 27/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1561 - accuracy: 0.9499\n",
            "Epoch 28/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1539 - accuracy: 0.9507\n",
            "Epoch 29/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1835 - accuracy: 0.9481\n",
            "Epoch 30/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1676 - accuracy: 0.9481\n",
            "Epoch 31/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1966 - accuracy: 0.9415\n",
            "Epoch 32/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2184 - accuracy: 0.9315\n",
            "Epoch 33/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1823 - accuracy: 0.9462\n",
            "Epoch 34/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1250 - accuracy: 0.9656\n",
            "Epoch 35/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1401 - accuracy: 0.9572\n",
            "Epoch 36/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1345 - accuracy: 0.9621\n",
            "Epoch 37/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2906 - accuracy: 0.8999\n",
            "Epoch 38/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2226 - accuracy: 0.9301\n",
            "Epoch 39/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9617\n",
            "Epoch 40/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1481 - accuracy: 0.9569\n",
            "Epoch 41/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1294 - accuracy: 0.9637\n",
            "Epoch 42/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1643 - accuracy: 0.9516\n",
            "Epoch 43/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1439 - accuracy: 0.9556\n",
            "Epoch 44/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1267 - accuracy: 0.9624\n",
            "Epoch 45/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1941 - accuracy: 0.9437\n",
            "Epoch 46/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1989 - accuracy: 0.9433\n",
            "Epoch 47/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3968 - accuracy: 0.8906\n",
            "Epoch 48/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3105 - accuracy: 0.9109\n",
            "Epoch 49/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3002 - accuracy: 0.9012\n",
            "Epoch 50/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2400 - accuracy: 0.9225\n",
            "Epoch 51/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.3677 - accuracy: 0.8738\n",
            "Epoch 52/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1400 - accuracy: 0.9566\n",
            "Epoch 53/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1383 - accuracy: 0.9569\n",
            "Epoch 54/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1258 - accuracy: 0.9618\n",
            "Epoch 55/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1053 - accuracy: 0.9675\n",
            "Epoch 56/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1098 - accuracy: 0.9664\n",
            "Epoch 57/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.2176 - accuracy: 0.9374\n",
            "Epoch 58/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1629 - accuracy: 0.9509\n",
            "Epoch 59/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1437 - accuracy: 0.9581\n",
            "Epoch 60/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1269 - accuracy: 0.9612\n",
            "Epoch 61/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1170 - accuracy: 0.9646\n",
            "Epoch 62/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2354 - accuracy: 0.9309\n",
            "Epoch 63/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1679 - accuracy: 0.9466\n",
            "Epoch 64/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1095 - accuracy: 0.9691\n",
            "Epoch 65/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1522 - accuracy: 0.9550\n",
            "Epoch 66/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1189 - accuracy: 0.9651\n",
            "Epoch 67/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1059 - accuracy: 0.9684\n",
            "Epoch 68/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1088 - accuracy: 0.9677\n",
            "Epoch 69/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1120 - accuracy: 0.9639\n",
            "Epoch 70/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1306 - accuracy: 0.9609\n",
            "Epoch 71/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0992 - accuracy: 0.9698\n",
            "Epoch 72/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0936 - accuracy: 0.9729\n",
            "Epoch 73/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0803 - accuracy: 0.9762\n",
            "Epoch 74/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0827 - accuracy: 0.9747\n",
            "Epoch 75/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1015 - accuracy: 0.9689\n",
            "Epoch 76/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1823 - accuracy: 0.9450\n",
            "Epoch 77/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.1104 - accuracy: 0.9664\n",
            "Epoch 78/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0830 - accuracy: 0.9751\n",
            "Epoch 79/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0857 - accuracy: 0.9726\n",
            "Epoch 80/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0859 - accuracy: 0.9741\n",
            "Epoch 81/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0982 - accuracy: 0.9714\n",
            "Epoch 82/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1423 - accuracy: 0.9606\n",
            "Epoch 83/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0973 - accuracy: 0.9714\n",
            "Epoch 84/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1084 - accuracy: 0.9697\n",
            "Epoch 85/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1050 - accuracy: 0.9680\n",
            "Epoch 86/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1707 - accuracy: 0.9509\n",
            "Epoch 87/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1451 - accuracy: 0.9553\n",
            "Epoch 88/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0989 - accuracy: 0.9714\n",
            "Epoch 89/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2003 - accuracy: 0.9420\n",
            "Epoch 90/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1232 - accuracy: 0.9643\n",
            "Epoch 91/100\n",
            "70/70 [==============================] - 1s 10ms/step - loss: 0.0910 - accuracy: 0.9725\n",
            "Epoch 92/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0961 - accuracy: 0.9726\n",
            "Epoch 93/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0835 - accuracy: 0.9739\n",
            "Epoch 94/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1442 - accuracy: 0.9572\n",
            "Epoch 95/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.0994 - accuracy: 0.9684\n",
            "Epoch 96/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.6652 - accuracy: 0.7326\n",
            "Epoch 97/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.2178 - accuracy: 0.9207\n",
            "Epoch 98/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1606 - accuracy: 0.9501\n",
            "Epoch 99/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1112 - accuracy: 0.9675\n",
            "Epoch 100/100\n",
            "70/70 [==============================] - 1s 9ms/step - loss: 0.1171 - accuracy: 0.9656\n",
            "4 Parameters: batch_size: 200 - epochs: 100 LR_unit: 0.1 Hidden_Unit: 50 Accuracy: 0.9618333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### With Best Hyperparametrs RNN/LSTM model\n",
        "D=1   # As we have only 1 feature as \"traffic\"\n",
        "X = X.reshape(-1, T, 1) # make it N x T x D\n",
        "N=20000\n",
        "T=10\n",
        "# make the RNN\n",
        "i = Input(shape=(T, D))\n",
        "x = LSTM(50)(i)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "model = Model(i, x)\n",
        "model.compile(\n",
        " loss='sparse_categorical_crossentropy',\n",
        "# loss='binary_crossentropy',\n",
        "  optimizer=Adam(lr=0.05),\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# train the RNN\n",
        "r = model.fit(\n",
        "  X_train,y_train,\n",
        "  batch_size=300,\n",
        "  epochs=100,\n",
        "  validation_data=(X_test,y_test),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0swnJmEhXGS",
        "outputId": "3a028d9a-d4ab-44b8-b056-cff2d2650b24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "47/47 [==============================] - 3s 37ms/step - loss: 1.0663 - accuracy: 0.5184 - val_loss: 0.5976 - val_accuracy: 0.7518\n",
            "Epoch 2/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.4469 - accuracy: 0.8246 - val_loss: 0.2807 - val_accuracy: 0.9023\n",
            "Epoch 3/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.2595 - accuracy: 0.9051 - val_loss: 0.1677 - val_accuracy: 0.9398\n",
            "Epoch 4/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.1868 - accuracy: 0.9314 - val_loss: 0.2195 - val_accuracy: 0.9157\n",
            "Epoch 5/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.1749 - accuracy: 0.9374 - val_loss: 0.1398 - val_accuracy: 0.9563\n",
            "Epoch 6/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.1390 - accuracy: 0.9519 - val_loss: 0.1289 - val_accuracy: 0.9627\n",
            "Epoch 7/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.1495 - accuracy: 0.9479 - val_loss: 0.1448 - val_accuracy: 0.9465\n",
            "Epoch 8/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.1301 - accuracy: 0.9574 - val_loss: 0.1150 - val_accuracy: 0.9555\n",
            "Epoch 9/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.1239 - accuracy: 0.9590 - val_loss: 0.1205 - val_accuracy: 0.9637\n",
            "Epoch 10/100\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 0.1129 - accuracy: 0.9625 - val_loss: 0.1091 - val_accuracy: 0.9618\n",
            "Epoch 11/100\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 0.1151 - accuracy: 0.9619 - val_loss: 0.1048 - val_accuracy: 0.9668\n",
            "Epoch 12/100\n",
            "47/47 [==============================] - 1s 20ms/step - loss: 0.0886 - accuracy: 0.9694 - val_loss: 0.1023 - val_accuracy: 0.9657\n",
            "Epoch 13/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.1102 - accuracy: 0.9643 - val_loss: 0.0815 - val_accuracy: 0.9745\n",
            "Epoch 14/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0965 - accuracy: 0.9686 - val_loss: 0.1004 - val_accuracy: 0.9652\n",
            "Epoch 15/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0899 - accuracy: 0.9695 - val_loss: 0.1143 - val_accuracy: 0.9648\n",
            "Epoch 16/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0867 - accuracy: 0.9726 - val_loss: 0.0924 - val_accuracy: 0.9717\n",
            "Epoch 17/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0856 - accuracy: 0.9734 - val_loss: 0.0966 - val_accuracy: 0.9663\n",
            "Epoch 18/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0942 - accuracy: 0.9712 - val_loss: 0.0705 - val_accuracy: 0.9768\n",
            "Epoch 19/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0829 - accuracy: 0.9725 - val_loss: 0.1179 - val_accuracy: 0.9590\n",
            "Epoch 20/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0830 - accuracy: 0.9719 - val_loss: 0.1204 - val_accuracy: 0.9605\n",
            "Epoch 21/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0916 - accuracy: 0.9705 - val_loss: 0.0701 - val_accuracy: 0.9795\n",
            "Epoch 22/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0817 - accuracy: 0.9729 - val_loss: 0.0751 - val_accuracy: 0.9767\n",
            "Epoch 23/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0810 - accuracy: 0.9746 - val_loss: 0.0733 - val_accuracy: 0.9765\n",
            "Epoch 24/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0874 - accuracy: 0.9724 - val_loss: 0.1507 - val_accuracy: 0.9518\n",
            "Epoch 25/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0939 - accuracy: 0.9678 - val_loss: 0.0697 - val_accuracy: 0.9800\n",
            "Epoch 26/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: 0.0660 - val_accuracy: 0.9793\n",
            "Epoch 27/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0705 - accuracy: 0.9792 - val_loss: 0.0861 - val_accuracy: 0.9732\n",
            "Epoch 28/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0840 - accuracy: 0.9728 - val_loss: 0.1118 - val_accuracy: 0.9638\n",
            "Epoch 29/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0866 - accuracy: 0.9729 - val_loss: 0.0955 - val_accuracy: 0.9677\n",
            "Epoch 30/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0813 - accuracy: 0.9737 - val_loss: 0.0771 - val_accuracy: 0.9760\n",
            "Epoch 31/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 0.0920 - val_accuracy: 0.9707\n",
            "Epoch 32/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0715 - accuracy: 0.9781 - val_loss: 0.0835 - val_accuracy: 0.9755\n",
            "Epoch 33/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0698 - accuracy: 0.9773 - val_loss: 0.0582 - val_accuracy: 0.9827\n",
            "Epoch 34/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0653 - accuracy: 0.9793 - val_loss: 0.0579 - val_accuracy: 0.9828\n",
            "Epoch 35/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0663 - accuracy: 0.9790 - val_loss: 0.0618 - val_accuracy: 0.9807\n",
            "Epoch 36/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0677 - accuracy: 0.9795 - val_loss: 0.0934 - val_accuracy: 0.9682\n",
            "Epoch 37/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0742 - accuracy: 0.9766 - val_loss: 0.0579 - val_accuracy: 0.9830\n",
            "Epoch 38/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0744 - accuracy: 0.9761 - val_loss: 0.0861 - val_accuracy: 0.9735\n",
            "Epoch 39/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0615 - accuracy: 0.9810 - val_loss: 0.0823 - val_accuracy: 0.9722\n",
            "Epoch 40/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0626 - accuracy: 0.9809 - val_loss: 0.0729 - val_accuracy: 0.9768\n",
            "Epoch 41/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.1188 - val_accuracy: 0.9597\n",
            "Epoch 42/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0706 - accuracy: 0.9758 - val_loss: 0.0647 - val_accuracy: 0.9795\n",
            "Epoch 43/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0673 - accuracy: 0.9781 - val_loss: 0.0584 - val_accuracy: 0.9818\n",
            "Epoch 44/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.0628 - val_accuracy: 0.9822\n",
            "Epoch 45/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0570 - accuracy: 0.9827 - val_loss: 0.0630 - val_accuracy: 0.9780\n",
            "Epoch 46/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0663 - accuracy: 0.9796 - val_loss: 0.0615 - val_accuracy: 0.9805\n",
            "Epoch 47/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.0749 - val_accuracy: 0.9777\n",
            "Epoch 48/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0523 - accuracy: 0.9834 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
            "Epoch 49/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0707 - accuracy: 0.9784 - val_loss: 0.0784 - val_accuracy: 0.9728\n",
            "Epoch 50/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.0689 - val_accuracy: 0.9795\n",
            "Epoch 51/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0676 - accuracy: 0.9774 - val_loss: 0.0697 - val_accuracy: 0.9807\n",
            "Epoch 52/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0748 - accuracy: 0.9764 - val_loss: 0.1138 - val_accuracy: 0.9637\n",
            "Epoch 53/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.0955 - val_accuracy: 0.9718\n",
            "Epoch 54/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0803 - accuracy: 0.9745 - val_loss: 0.0663 - val_accuracy: 0.9802\n",
            "Epoch 55/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0710 - accuracy: 0.9764 - val_loss: 0.0715 - val_accuracy: 0.9765\n",
            "Epoch 56/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0710 - accuracy: 0.9766 - val_loss: 0.0742 - val_accuracy: 0.9817\n",
            "Epoch 57/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0565 - accuracy: 0.9824 - val_loss: 0.1065 - val_accuracy: 0.9680\n",
            "Epoch 58/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0665 - accuracy: 0.9783 - val_loss: 0.0555 - val_accuracy: 0.9842\n",
            "Epoch 59/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0527 - accuracy: 0.9841 - val_loss: 0.0516 - val_accuracy: 0.9838\n",
            "Epoch 60/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.0587 - val_accuracy: 0.9817\n",
            "Epoch 61/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0545 - accuracy: 0.9830 - val_loss: 0.0616 - val_accuracy: 0.9802\n",
            "Epoch 62/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.0687 - val_accuracy: 0.9798\n",
            "Epoch 63/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0575 - accuracy: 0.9820 - val_loss: 0.0722 - val_accuracy: 0.9770\n",
            "Epoch 64/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0698 - accuracy: 0.9781 - val_loss: 0.1081 - val_accuracy: 0.9645\n",
            "Epoch 65/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0639 - accuracy: 0.9789 - val_loss: 0.1311 - val_accuracy: 0.9492\n",
            "Epoch 66/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 0.0733 - val_accuracy: 0.9772\n",
            "Epoch 67/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0532 - accuracy: 0.9836 - val_loss: 0.0577 - val_accuracy: 0.9818\n",
            "Epoch 68/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0529 - accuracy: 0.9838 - val_loss: 0.0838 - val_accuracy: 0.9725\n",
            "Epoch 69/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0531 - accuracy: 0.9830 - val_loss: 0.0628 - val_accuracy: 0.9798\n",
            "Epoch 70/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0628 - val_accuracy: 0.9812\n",
            "Epoch 71/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 0.0601 - val_accuracy: 0.9818\n",
            "Epoch 72/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0602 - val_accuracy: 0.9843\n",
            "Epoch 73/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.0530 - val_accuracy: 0.9832\n",
            "Epoch 74/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0613 - accuracy: 0.9814 - val_loss: 0.0669 - val_accuracy: 0.9808\n",
            "Epoch 75/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.0779 - val_accuracy: 0.9773\n",
            "Epoch 76/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0612 - accuracy: 0.9814 - val_loss: 0.0771 - val_accuracy: 0.9762\n",
            "Epoch 77/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0612 - val_accuracy: 0.9813\n",
            "Epoch 78/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.0596 - val_accuracy: 0.9820\n",
            "Epoch 79/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0500 - accuracy: 0.9841 - val_loss: 0.0672 - val_accuracy: 0.9793\n",
            "Epoch 80/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.0737 - val_accuracy: 0.9752\n",
            "Epoch 81/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0707 - accuracy: 0.9773 - val_loss: 0.0683 - val_accuracy: 0.9803\n",
            "Epoch 82/100\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 0.0521 - accuracy: 0.9842 - val_loss: 0.0675 - val_accuracy: 0.9768\n",
            "Epoch 83/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.0726 - val_accuracy: 0.9775\n",
            "Epoch 84/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0532 - val_accuracy: 0.9837\n",
            "Epoch 85/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.0589 - val_accuracy: 0.9833\n",
            "Epoch 86/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0794 - val_accuracy: 0.9743\n",
            "Epoch 87/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0643 - accuracy: 0.9798 - val_loss: 0.0678 - val_accuracy: 0.9792\n",
            "Epoch 88/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0508 - accuracy: 0.9830 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 89/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0620 - accuracy: 0.9803 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
            "Epoch 90/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0541 - accuracy: 0.9834 - val_loss: 0.0600 - val_accuracy: 0.9817\n",
            "Epoch 91/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.0712 - val_accuracy: 0.9793\n",
            "Epoch 92/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0500 - accuracy: 0.9834 - val_loss: 0.0689 - val_accuracy: 0.9788\n",
            "Epoch 93/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.0533 - val_accuracy: 0.9855\n",
            "Epoch 94/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0383 - accuracy: 0.9882 - val_loss: 0.0681 - val_accuracy: 0.9827\n",
            "Epoch 95/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0409 - accuracy: 0.9875 - val_loss: 0.0702 - val_accuracy: 0.9795\n",
            "Epoch 96/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.0948 - val_accuracy: 0.9723\n",
            "Epoch 97/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0835 - accuracy: 0.9741 - val_loss: 0.0595 - val_accuracy: 0.9813\n",
            "Epoch 98/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0561 - accuracy: 0.9829 - val_loss: 0.0550 - val_accuracy: 0.9838\n",
            "Epoch 99/100\n",
            "47/47 [==============================] - 1s 18ms/step - loss: 0.0550 - accuracy: 0.9828 - val_loss: 0.0637 - val_accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "47/47 [==============================] - 1s 17ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.1361 - val_accuracy: 0.9545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat=[]\n",
        "for pred in predictions:\n",
        "  y_hat.append(pred.argmax())\n",
        "  \n",
        "print('Accuracy of  Neural Network Classifier on test set: {:.2f}'.format(metrics.accuracy_score(y_test,y_hat) ))\n",
        "print(confusion_matrix(y_test,y_hat))\n",
        "print(classification_report(y_test,y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL6RQZ_sRrEI",
        "outputId": "47acd3a2-f65c-49e0-d874-79437bbe230b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of  Neural Network Classifier on test set: 0.98\n",
            "[[1484    1    0    0]\n",
            " [  28 1501    3    0]\n",
            " [   0   53 1422   36]\n",
            " [   0    0   16 1456]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      1.00      0.99      1485\n",
            "         1.0       0.97      0.98      0.97      1532\n",
            "         2.0       0.99      0.94      0.96      1511\n",
            "         3.0       0.98      0.99      0.98      1472\n",
            "\n",
            "    accuracy                           0.98      6000\n",
            "   macro avg       0.98      0.98      0.98      6000\n",
            "weighted avg       0.98      0.98      0.98      6000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B_TVK9edRsep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}